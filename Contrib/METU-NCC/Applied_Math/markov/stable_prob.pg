##DESCRIPTION
##ENDDESCRIPTION
## DBsubject(Linear algebra)
## DBchapter(Matrices)
## DBsection(Markov chains)
## Institution(METU-NCC)
## Author(Benjamin Walter)
## Level(3)
## KEYWORDS('markov')

DOCUMENT();        # This should be the first executable line in the problem.

loadMacros(
"PGstandard.pl",
"MathObjects.pl",
"PGcourse.pl",
"PGbasicmacros.pl",
"PGchoicemacros.pl",
"parserVectorUtils.pl"
);

TEXT(beginproblem());

Context('Matrix');

@t = ([ random(1,9,1), 0 ],
      [ random(1,9,1), 0 ]);

for (my $i=0; $i<2; $i++) {
  $t[$i][1] = 10 - $t[$i][0];
}

$T = 1/10 * Matrix( @t )->transpose;

@info1 = (
  "\(\frac{$t[0][0]}{10}\) of the time you remain in state 1",
  "\(\frac{$t[0][1]}{10}\) of the time you change to state 2"
);
@info2 = (
  "\(\frac{$t[1][0]}{10}\) of the time you change to state 1",
  "\(\frac{$t[1][1]}{10}\) of the time you remain in state 2"
);


@info1 = @info1[random(0,1,1),1];
@info2 = @info2[random(0,1,1),1];

@v_s = ($t[1][0], 10 - $t[0][0]);
$vs = 1/($t[1][0] + 10 - $t[0][0]) * ColumnVector( @v_s );

Context()->texStrings;

BEGIN_TEXT

A Markov system with two states satisfies the following rule.
$BR
\(\bullet \quad\)
If you are in state 1 then $info1[0].
$BR
\(\bullet \quad\)
If you are in state 2 then $info2[1].

$PAR

Write the transition matrix for this system using the state vector
\(v = \left[\begin{matrix}
 \text{state 1} \\ 
 \text{state 2} 
\end{matrix}\right]. \)

$PAR

\(\quad \mathrm{T} = \) \{ $T->ans_array(2) \}

$PAR
$HR
$PAR

Find the long term probability (stable state vector).

\(\mathbf{v}_s = \) \{ $vs->ans_array() \}


END_TEXT

Context()->normalStrings;

ANS( $T->cmp() );
ANS( $vs->cmp() );


ENDDOCUMENT();        # This should be the last executable line in the problem.



